# BetterMixture Team 12345678 报告

    bebetterest[at]outlook.com
    yubsog[at]163.com

🤯简洁概括+复现指引：[here](https://github.com/parallelsucc/12345678-Solution-of-BetterMixture/tree/reproduction)

## 引言
[BetterMixture 挑战赛](https://tianchi.aliyun.com/competition/entrance/532174)要求在给定的计算量约束下(固定绝大部分训练参数&训练 token 总数不超过 10M)，通过巧妙的数据配比和智能采样，实现对大模型的高效率微调，充分挖掘“以数据为中心”的模型潜力。该报告旨在分享初/复赛的实验结果(见附录)及分析。从初赛 7 个公开数据集，到复赛扩展的私有数据集，我们不断尝试迭代优化，最终获得了一些指标的提升。希望该报告及相关实验结果能够对读者有所启发。

## 数据集及指标

BetterMixture 中训练数据集来自于 Alpaca-CoT 中的20个数据集(alpaca_data、alpaca_gpt4_data、alpaca_gpt4_data_zh、belle_data0.5M_cn、COIG_translate_en、COIG_translate_zh、dolly、finance_en、gpt4all、GPTeacher、instinwild_ch、instinwild_en、instruct、sharegpt_zh、sharegpt、Vicuna、HC3_ChatGPT、HC3_Human、HC3_Chinese_ChatGPT、HC3_Chinese_Human)，初赛测试数据集为一些公开测试基准(ARC、HellaSwag、TruthfulQA、MMLU、GSM8K、CMMLU、SummScreen)的子集；复赛训练数据集与初赛数据集一致，复赛测试数据集未知。每个单项任务的成绩由模型在该任务上的评测得分与 Baichuan2-7B-Base 基准得分的比值确定，而综合成绩是所有单项任务比值的平均值。

## 初赛

|          | score    | arc_challenge | hellaswag | truthfulqa_mc | hendrycksTest-* | cmmlu-*  | gsm8k  | scrolls_summscreenfd |
|----------|----------|---------------|-----------|---------------|-----------------|----------|----------|----------------------|
| Baseline | 1.138470 | 1.056604      | 0.973684  | 1.238196      | 0.998718        | 0.990755 | 0.444444 | 2.266888             |
| Final    | 1.483872 | 1.037736      | 0.986842  | 1.343258      | 0.997116        | 0.995773 | 1.611111 | 3.415265             |

我们按原数据比例采样、随机混合，得到 baseline。

一开始，我们有两个思路，一是选择与测试数据集内容相近的训练数据(plan.1)，二是首先测试单数据集的表现从而指导后续的数据策略(plan.6-plan.17)。在测试单数据集表现时，使用 data-juicer 设置7个指标（alnum_ratio，char_rep_ratio，lang，lang_score，perplexity，text_len，word_rep_ratio）的阈值试图滤除异常点而保留大多数数据。意外中，我们发现其实不通过阈值筛选的 HC3_ChatGPT 最好，truthfulqa_mc 亮眼，而 scrolls_summscreenfd 表现也不错。

基于此，我们将 HC3_ChatGPT 作为数据主干从数据量/筛选方式两方面进行进一步调整(plan.18/19/25/29/30)，并额外尝试加入其它数据，如引入 gpt4 生成的 alpaca_gpt4_data (plan.37)，效果并不理想，或许是7B模型相对较小，还无法通过微调直接学习到“大佬”能力。而修改数据混合策略，先在 alpaca_gpt4_data 试图学习 gpt4 能力的皮毛，再在 HC3_ChatGPT 上增强具体的能力也未见提升(plan.38)。

观察实验结果的浮动和其他队伍的表现，我们将注意力放在 scrolls_summscreenfd 和 gsm8k 测试集上。scrolls_summscreenfd 针对长文本，筛选 HC3_ChatGPT 中的较长文本进行实验 (plan.29)，并不理想；gsm8k 的运算表示有明显的格式特点，引入正则匹配筛选的运算数据。运算数据的引入甚至能够帮助含数学推理数据的 belle_data0.5M_cn 提升 gsm8k 的表现(plan.32)，即使整体效果有所下降。通过结合运算数据和 HC3_ChatGPT，我们获得了更好的效果(plan.39)；运算数据比较少，但通过重复引入该数据的方式并不能带来效果的提升(plan.42)；筛选后运算数据含有一些网页源代码的内容，通过一些 html 标识符号去除(plan.47)，并在后续其他数据沿用相同的方式去除网页源码。

另外，当不启用 SFT_PACKING(plan.40)，表现明显提升。我们认为这是由于 SFT_PACKING 可能将多个不同类型的样本整合在一起，微调反而让这个7B模型不知所措了。

由于随机混合可能使得不同数据源的样本不均匀，我们继续尝试调整混合策略(plan.41)，将数据分为 60 组，每组内各数据集的样本数目一致从而确保模型能够在微调全过程相对均匀地接触各数据集的样本，组内样本顺序随机，无明显提升；注意到 truthfulqa_mc 基本是一些较短的问答数据，因此尝试过滤出 Who、When、Why 等提问开头的短指令数据进行微调(plan.45)，没有明显提升。至此为止最好的方案仅仅是 HC3_ChatGPT 与运算数据的结合，还有较多 token 余量，因此尝试引入其他数据集(plan.48)，丰富多样性，没有明显提升，这或许说明质量比数量更重要。

scrolls_summscreenfd 有较大改进空间，沿用筛选长文本的逻辑，通过观察每个训练数据集长文本的样本质量，我们选择引入 dolly 和 instruct 中 token 数目不低于1000的数据(plan.49)。在此基础上，考虑到中文数据或许质量略差，我们去除了所有中文数据(plan.53/55)，得到了更好的结果(1.457905)。后续又分别探究了长文本 dolly 和 instruct 的作用(plan.60/61)，发现去除 dolly 长文本效果反而更好(1.482502)，或许是因为 dolly 是金融相关的长文本，与剧本摘要生成并不相关，且测试集中的金融相关数据并不是长文本。

最终初赛最好成绩为1.483872(第三)，其方案(plan.64)为 HC3_ChatGPT 英文数据抽取15000条，instruct 长文本数据(>1k tokens)共3366条，与运算数据(3794条来自 instruct；2339条来自 gpt4all)结合，共计9.07M tokens，不启用 SFT_PACKING。

## 复赛

由于复赛测试数据为拓展的私有数据集，并不能具体分析目标域的特点，因此这里我们的提升主要在于根据某些衡量指标进行数据的调整。

由于此前方案单独添加了长文本数据，而 HC3_ChatGPT 的长文本并不会对 scrolls_summscreenfd 有提升，我们仅保留较短(<500tokens)的 HC3_ChatGPT 数据(plan.f24)；基于初赛将明确的中文数据源去除(plan.53/55)所带来的提升，我们通过设置 lang_score 阈值得到质量更高的英文数据(plan.f24)；考虑到高 ppl 可能对应异常数据，也可能对模型来说难度比较大，微调并不能得到很好的效果, 我们设置 ppl 的上限(plan.f24);较小的 ppl 可能又在模型舒适圈内，并不会从中学到什么不同，通过 ppl 下限滤除(plan.f25)。通过调整各阈值，我们控制过滤后的数据量，从而取消随机采样，避免采样的随机性。

最终，复赛最好成绩(plan.f32)为1.644257(第一)，其方案增量为 HC3_ChatGPT 保留ppl箱图分布 25%～75%区间、language_score 不低于0.9的数据共13365条；instruct 保留保留ppl箱图分布 0%～75%区间、language_score 不低于0.7的数据共1754条。

## 总结

一些针对本赛题的可能性结论：

- 对于前面提到的测试数据，HC3_ChatGPT 数据集的综合质量比其他单一数据集更高。
- 筛选出质量较好的长文本数据（如从 instruct 中）能够提升在 scrolls_summscreenfd 上的表现，但同时也有 <font size=4>__可能__ </font> 会削弱模型在其他测试集上的表现。
- 筛选出运算形式类似的数学数据(如从 instruct、gpt4all 中)能够提升在 gsm8k 上的表现，但同时也有 <font size=4>__可能__ </font> 会削弱模型在其他测试集上的表现。
- 在我们的方案中，SFT_PACKING 会使微调模型效果变差。

一些具有更多普遍性的可能性结论:

- 高质量数据对模型微调效果更好，数据并不一定越多越好。
- 筛选策略上，合适的 ppl 和 language_id_score 阈值能够得到更好的微调数据。
- 在我们的方案中，混合的策略和随机混合相比差异不大。

<font color=Sykblue size=3>本报告若有任何不妥或有误之处，欢迎联系修正。</font>

## 附录：初赛实验结果

| plan    | detail                                                                                                                                                                                                    | score    | arc_challenge | hellaswag | truthfulqa_mc | hendrycksTest-* | cmmlu-*  | gsm8k    | scrolls_summscreenfd |
|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|---------------|-----------|---------------|-----------------|----------|----------|----------------------|
| plan.1  | 测试多为问答，65000仅取alpaca_gpt4_data(30000,15000)、dolly(9997)、finance_en(2003)                                                                                                                       | 1.229311 | 1.037736      | 1.013158  | 1.166904      | 0.993271        | 0.995245 | 0.722222 | 2.676639             |
| plan.6  | 仅用Vicuna                                                                                                                                                                                                |  1.25231 | 1.075472      | 0.960526  | 0.979071      | 1.001922        | 0.997094 | 0.777778 | 2.974308             |
| plan.7  | HC3_Chinese_Human(20000), HC3_Human(40000)                                                                                                                                                                | 1.087333 | 1.018868      | 1.026316  | 0.963370      | 0.993592        | 0.992604 | 0.000000 | 2.616585             |
| plan.8  | HC3_Chinese_gpt(12596), HC3_gpt(19741)                                                                                                                                                                    | 1.277605 | 1.056604      | 0.973684  | 1.233724      | 0.975328        | 1.003697 | 0.611111 | 3.089090             |
| plan.9  | 不筛选，HC3_Chinese_gpt(12596), HC3_gpt(19741)                                                                                                                                                            | 1.319703 | 1.056604      | 0.986842  | 1.279160      | 0.979494        | 1.004490 | 0.833333 | 3.098000             |
| plan.10 | coig(en40000,zh40000)                                                                                                                                                                                     | 1.046447 | 1.037736      | 0.973684  | 0.956126      | 0.991028        | 1.001320 | 0.000000 | 2.365236             |
| plan.11 | instruct(60000)                                                                                                                                                                                           | 1.038172 | 1.018868      | 0.986842  | 1.267323      | 0.979494        | 0.999207 | 0.444444 | 1.571027             |
| plan.12 | instinwild_en(40000), instinwild_ch(20000)                                                                                                                                                                | 1.278791 | 1.018868      | 0.934211  | 0.975849      | 0.989426        | 0.992340 | 1.000000 | 3.040846             |
| plan.13 | share-gpt(4w,2w)                                                                                                                                                                                          | 1.240691 | 1.018868      | 1.000000  | 1.254103      | 0.994873        | 1.003433 | 0.777778 | 2.635781             |
| plan.14 | belle_data0.5M_cn(6w) 不筛选                                                                                                                                                                              | 1.262525 | 1.000000      | 0.986842  | 1.173788      | 1.000961        | 0.983095 | 1.000000 | 2.692992             |
| plan.15 | gpt4all 6w                                                                                                                                                                                                | 1.089509 | 1.037736      | 0.986842  | 1.295094      | 0.983979        | 0.992340 | 0.722222 | 1.608349             |
| plan.16 | GPTeacher(33548) 不筛选                                                                                                                                                                                   | 1.215343 | 1.094340      | 0.986842  | 1.012864      | 1.000320        | 0.995245 | 0.722222 | 2.695569             |
| plan.17 | alpaca_gpt4_data(3w,3w)                                                                                                                                                                                   | 1.256705 | 1.056604      | 1.013158  | 1.206016      | 0.995514        | 0.994453 | 0.777778 | 2.753414             |
| plan.18 | HC3_Chinese_ChatGPT（17522），不筛选,2.56M tokens                                                                                                                                                         |  1.21416 | 1.000000      | 0.973684  | 1.099174      | 0.990708        | 0.989962 | 1.111111 | 2.334480             |
| plan.19 | HC3_ChatGPT(26903), 不筛选, 7.54tokens                                                                                                                                                                    | 1.284965 | 1.000000      | 1.013158  | 1.240258      | 0.986222        | 1.010565 | 0.666667 | 3.077885             |
| plan.25 | 9，不限制数目（en26903，cn17521）                                                                                                                                                                         | 1.298469 | 1.000000      | 0.986842  | 1.291359      | 0.977251        | 0.985736 | 0.722222 | 3.125874             |
| plan.28 | HC3_ChatGPT(19000),instinwild_en(20000), instinwild_ch(20000)                                                                                                                                             | 1.266353 | 0.981132      | 0.973684  | 1.192567      | 0.985261        | 1.001584 | 0.722222 | 3.008021             |
| plan.29 | HC3_ChatGPT根据长度筛选: cn: 140-2000(12691); en: 956-10000(19248)                                                                                                                                        | 1.297339 | 1.018868      | 0.986842  | 1.288954      | 0.985581        | 0.996566 | 0.833333 | 2.971230             |
| plan.30 | 不筛选，HC3_Chinese_gpt(9000), HC3_gpt(15000) (5.52Mtokens)                                                                                                                                               |   1.3077 | 1.056604      | 0.986842  | 1.226721      | 0.979173        | 1.001584 | 0.888889 | 3.014090             |
| plan.32 | 数学➕belle_data0.5M_cn                                                                                                                                                                                    | 1.063588 | 1.018868      | 1.000000  | 1.021199      | 0.997757        | 0.994453 | 1.055556 | 1.357284             |
| plan.36 | share-gpt(2w, 1w), belle_data0.5M_cn(3w) (不筛选) (10.00Mtokens。。。)                                                                                                                                    | 1.192847 | 1.018868      | 0.986842  | 1.206048      | 1.000320        | 0.999207 | 0.666667 | 2.471979             |
| plan.37 | 不筛选，HC3_Chinese_gpt(9000), HC3_gpt(15000),alpaca_gpt4_data(1.5w,1w)(10.00Mtokens)                                                                                                                     | 1.299994 | 1.037736      | 0.986842  | 1.307733      | 0.994553        | 0.994981 | 0.944444 | 2.833666             |
| plan.38 | 37, 修改混合策略，（4个数据集全部shuffle------->shuffle两个alpaca, shuffle两个HC3，最后拼起来，不shuffle）（先跑alpaca,再跑hc3）                                                                          | 1.298113 | 1.018868      | 0.973684  | 1.284815      | 0.995514        | 0.994981 | 0.888889 | 2.930044             |
| plan.39 | 不筛选，HC3_Chinese_gpt(9000), HC3_gpt(15000),加数学(5.57Mtokens)                                                                                                                                         | 1.376375 | 1.018868      | 0.986842  | 1.222377      | 0.989106        | 0.999999 | 1.277778 | 3.139658             |
| plan.40 | 39，SFT_PACKING=False (5.57Mtokens)                                                                                                                                                                       | 1.433508 | 1.075472      | 1.000000  | 1.394632      | 1.000000        | 0.984944 | 1.277778 | 3.301731             |
| plan.41 | 不筛选，HC3_Chinese_gpt(10000), HC3_gpt(16000),加数学。num_group=60(60组,组内shuffle），SFT_PACKING=False，（6.19Mtokens）                                                                                | 1.400522 | 1.018868      | 0.986842  | 1.394690      | 0.996475        | 0.989698 | 1.166667 | 3.250416             |
| plan.42 | HC3_Chinese_gpt(10000), HC3_gpt(16000),加两次数学，SFT_PACKING=False，6.41Mtokens                                                                                                                         | 1.420574 | 1.075472      | 0.986842  | 1.381636      | 0.990387        | 0.986265 | 1.222222 | 3.301194             |
| plan.45 | 40+mc类型问题数据 (6.96Mtokens)                                                                                                                                                                           | 1.291044 | 1.037736      | 1.026316  | 1.214501      | 0.993592        | 0.982831 | 0.888889 | 2.893444             |
| plan.46 | 40+更多数学(7.63 )                                                                                                                                                                                        | 1.409037 | 1.056604      | 0.986842  | 1.386064      | 0.999679        | 0.985472 | 1.444444 | 3.004154             |
| plan.47 | 46 数学中去除网页源代码样本  + 更多hc (9.26Mtokens)                                                                                                                                                       | 1.418577 | 1.075472      | 1.013158  | 1.395580      | 1.000320        | 0.981774 | 1.500000 | 2.963737             |
| plan.48 | HC3_Chinese_gpt(10000), HC3_gpt(16000),加更多数学，SFT_PACKING=False，《instinwild(en1000,cn500)，vicuna(600),share-gpt(en200,cn100),belle(200),GPTeacher(200),alpaca_gpt4_data(200)，其他20》8.24Mtokens | 1.346734 | 1.037736      | 0.973684  | 1.317326      | 0.997436        | 0.980718 | 1.333333 | 2.786904             |
| plan.49 | 46的math，HC3_Chinese_gpt(10000), HC3_gpt(15000)， 长文(>1000token: dolly200 instruct2000)  ,INT8=False ([35661] samples and [ 9.66 ] M tokens)                                                           | 1.420426 | 1.018868      | 0.986842  | 1.376273      | 0.993271        | 0.984416 | 1.277778 | 3.305535             |
| plan.52 | 39，lr=1e-3,(5.75Mtokens)                                                                                                                                                                                 | 1.347556 | 0.943396      | 1.013158  | 1.404212      | 0.993912        | 0.977020 | 0.833333 | 3.267864             |
| plan.53 | 49, hc-chinese取消，hc-gpt(15000), instruct3000 Total [26702] samples and [ 9.23 ] M tokens                                                                                                               | 1.421689 | 1.018868      | 1.013158  | 1.319770      | 0.987824        | 1.001848 | 1.222222 | 3.388134             |
| plan.54 | 53,去掉instruct和dolly Total [23502] samples and [ 5.95 ] M tokens                                                                                                                                        | 1.363244 | 1.037736      | 0.960526  | 1.284557      | 1.002883        | 1.000528 | 1.333333 | 2.923144             |
| plan.55 | 53,去掉math中的belle_cn Total [24329] samples and [ 8.90 ] M tokens                                                                                                                                       | 1.457905 | 1.056604      | 0.960526  | 1.311216      | 0.992310        | 0.998415 | 1.555556 | 3.330712             |
| plan.57 | 40，去掉hc-chinese和belle_cn sharegpt_zh Total [15875] samples and [ 4.44 ] M tokens                                                                                                                      |  1.44634 | 1.113208      | 1.000000  | 1.376337      | 1.008971        | 1.001584 | 1.333333 | 3.290947             |
| plan.59 | 57，更多数学 Total [21125] samples and [ 5.63 ] M tokens                                                                                                                                                  | 1.468606 | 1.000000      | 0.986842  | 1.367493      | 0.999359        | 0.996830 | 1.666667 | 3.263049             |
| plan.60 | 55，去掉dolly Total [24129] samples and [ 8.69 ] M tokens                                                                                                                                                 | 1.482502 | 1.056604      | 0.986842  | 1.321062      | 0.992951        | 1.001056 | 1.555556 | 3.463444             |
| plan.61 | 55，去掉instruct Total [21329] samples and [ 5.82 ] M tokens.                                                                                                                                             | 1.443152 | 1.037736      | 0.986842  | 1.286664      | 1.006728        | 0.998415 | 1.611111 | 3.174570             |
| plan.62 | 55,hc3用尽量长的数据(>200tokens) Total [24333] samples and [ 9.43 ] M tokens                                                                                                                              | 1.418301 | 1.037736      | 1.000000  | 1.303645      | 0.993912        | 1.011093 | 1.277778 | 3.303946             |
| plan.63 | 60 hc() Total [28629] samples and [ 9.96 ] M tokens                                                                                                                                                       | 1.437774 | 1.037736      | 1.000000  | 1.347548      | 0.999679        | 1.000528 | 1.388889 | 3.290040             |
| plan.64 | 60 instruct all Total [24495] samples and [ 9.07 ] M tokens                                                                                                                                               | 1.483872 | 1.037736      | 0.986842  | 1.343258      | 0.997116        | 0.995773 | 1.611111 | 3.415265             |

## 附录：复赛实验结果

| plan    | detail                                                                                                      | tokens                                       | score    | Reasoning | Common Sense | Truthfulness | Math     | English Knowledge | Chinese Knowledge | Summarization |
|---------|-------------------------------------------------------------------------------------------------------------|----------------------------------------------|----------|-----------|--------------|--------------|----------|-------------------|-------------------|---------------|
| plan.f0  | 64，不筛选，HC3_gpt(15000)，长文(>1000token: instruct all 3366)，加数学，SFT_PACKING=False ,INT8=False. | [ 9.07 ] M tokens                            | 1.561719 | 0.959184  | 0.987654     | 1.326721     | 1.285714 | 0.996764          | 1.009806          | 4.366187      |
| plan.f1  | 60，不筛选，HC3_gpt(15000)，长文(>1000token: instruct，3000)，加数学，SFT_PACKING=False ,INT8=True.     | [ 8.69 ] M tokens                            | 1.603067 | 0.959184  | 0.975309     | 1.337746     | 1.476190 | 0.982529          | 0.985501          | 4.505009      |
| plan.f24 | f1，hc3,token<500,lang_score>0.9，ppl<279.1                                                                  | Total [24133] samples and [ 8.70 ] M tokens. | 1.623323 | 0.938776  | 0.975309     | 1.351198     | 1.571429 | 0.991264          | 1.000135          | 4.535153      |
| plan.f25 | f24， instruct ppl>1170.6（整体箱图） lang_score>0.7  ==>1754                                                | Total [22887] samples and [ 7.43 ] M tokens. | 1.632045 | 0.959184  | 1.000000     | 1.321986     | 1.571429 | 0.988029          | 0.990461          | 4.593225      |
| plan.f32 | f25，更改hc3筛选策略，ppl25%-75%(min_ppl: 148.9max_ppl: 279.1),hc3,13365..                                   | Total [21251] samples and [ 7.06 ] M tokens. | 1.644257 | 0.979592  | 1.000000     | 1.344694     | 1.619048 | 0.994500          | 1.003039          | 4.568930      |
