# Process config example for dataset

# global parameters
project_name: 'HC3_ChatGPT'
dataset_path: './input/HC3_ChatGPT.jsonl'  # path to your dataset directory or file
np: 4  # number of subprocess to process your dataset

export_path: './output/analysis/HC3_ChatGPT/HC3_ChatGPT.jsonl'

# process schedule
# a list of several process operators with their arguments
process:
  - text_length_filter:
      min_len: 1
      max_len: 4096
    
  - language_id_score_filter:
      lang: 'en'
      
  - perplexity_filter:
      lang: 'en'
      max_ppl: 1500
      
  - text_length_filter:
      min_len: 1.0
      max_len: 10000
  # - token_num_filter:
  #     hf_tokenizer: "baichuan-inc/Baichuan2-7B-Base"
  #     min_num: 1
  #     max_num: 1024
  # - word_num_filter:
  
  - alphanumeric_filter:
      tokenization: False
      min_ratio: 0.8
      max_ratio: 1.0
  
  - character_repetition_filter:
      rep_len: 10
      min_ratio: 0.0 
      max_ratio: 0.3
      
  - word_repetition_filter:
      lang: 'en'
      tokenization: False
      rep_len: 10
      min_ratio: 0.0
      max_ratio: 0.5
    
  # - text_entity_dependency_filter
      
